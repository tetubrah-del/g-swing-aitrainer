"use server";

// ğŸ”¥ Server Actionsï¼šçµæœã‚’ JSON ã§è¿”ã™ã€‚redirect ã¯ä½¿ã‚ãªã„ã€‚

import {
  attachPoseKeypoints, defaultDetectKeypoints, determineSwingPhases
} from "../lib/pose/determineSwingPhases";
import { askVisionAPI } from "../lib/vision/askVisionAPI";
import { PhaseFrame } from "../lib/vision/extractPhaseFrames";

const OPENAI_API_BASE = process.env.OPENAI_API_BASE ?? "https://api.openai.com/v1";
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const VIDEO_EMBED_MODEL = "gpt-4o-vision-video-embed";

export const SWING_ANALYSIS_PROMPT = `
You are a professional golf swing analyzer.

ä¸ãˆã‚‰ã‚ŒãŸä»£è¡¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚‚ã¨ã«ã€æ—¥æœ¬èªã§è©³ç´°ãªã‚¹ã‚¤ãƒ³ã‚°åˆ†æã‚’è¡Œã„ã€
ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¤ JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€Œresultã€ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{
  "summary": "ã‚¹ã‚¤ãƒ³ã‚°å…¨ä½“ã®ç·è©•ï¼ˆ300ã€œ500æ–‡å­—ç¨‹åº¦ã§è©³ã—ãï¼‰",
  "issues": ["å…·ä½“çš„ãªå•é¡Œç‚¹ã‚’ç®‡æ¡æ›¸ãã§"],
  "cues": ["æ”¹å–„ã®ãŸã‚ã®çŸ­ã„ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚­ãƒ¥ãƒ¼ã‚’ç®‡æ¡æ›¸ãã§"],
  "priority": "æ”¹å–„ã™ã¹ãé …ç›®ã®å„ªå…ˆé †ä½ã‚’æ–‡ç« ã§è¨˜è¿°",
}

å¿…ãš JSON ã®ã¿å‡ºåŠ›ã—ã€å‰å¾Œã®æ–‡ç« ã¯æŒ¿å…¥ã—ãªã„ã“ã¨ã€‚
`;

type VideoEmbeddingFrame = {
  image: string;
  mime_type: string;
  timestamp: number;
};

type VideoEmbeddingResponse = {
  data?: Array<{ frames?: VideoEmbeddingFrame[] }>;
  error?: unknown;
};

export interface AnalyzeVideoResult {
  frames: PhaseFrame[];
  vision: unknown;
}

function assertOpenAIKey(value: string | undefined): string {
  if (!value) {
    throw new Error("OPENAI_API_KEY is not set");
  }
  return value;
}

async function createPhaseFramesFromVideo(file: File, buffer: Buffer): Promise<PhaseFrame[]> {
  const apiKey = assertOpenAIKey(OPENAI_API_KEY);

  const form = new FormData();
  const safeName = (file.name || "video.mp4").replace(/[^\w.\-]/g, "_");
  const mimeType = file.type && file.type.includes("/") ? file.type : "video/mp4";

  const nodeBlob = new Blob([buffer], { type: mimeType });
  form.append("file", nodeBlob, safeName);
  form.append("model", VIDEO_EMBED_MODEL);

  const response = await fetch(`${OPENAI_API_BASE}/embeddings-video`, {
    method: "POST",
    headers: { Authorization: `Bearer ${apiKey}` },
    body: form,
  });

  if (!response.ok) {
    const body = await response.text().catch(() => "");
    throw new Error(`Video embedding request failed: ${response.status} ${response.statusText} ${body}`);
  }

  const payload = (await response.json()) as VideoEmbeddingResponse;
  const frames = payload.data?.[0]?.frames ?? [];

  if (!frames.length) throw new Error("Embedding response did not include frames");

  const sortedLimited = [...frames].sort((a, b) => a.timestamp - b.timestamp).slice(0, 120);

  return sortedLimited.map((f) => ({
    id: `ts-${f.timestamp.toFixed(2)}`,
    base64Image: f.image,
    mimeType: f.mime_type,
    timestampSec: f.timestamp,
  }));
}

export async function analyzeVideo(formData: FormData): Promise<AnalyzeVideoResult> {
  const videoFile = formData.get("video");

  if (!(videoFile instanceof File)) {
    throw new Error("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„");
  }

  const arrayBuffer = await videoFile.arrayBuffer();
  const buffer = Buffer.from(arrayBuffer);

  // raw frames (120ãƒ•ãƒ¬ãƒ¼ãƒ )
  const rawFrames = await createPhaseFramesFromVideo(videoFile, buffer);

  // â˜… ãƒ•ã‚§ãƒ¼ã‚ºæŠ½å‡ºç”¨ fake pose ã‚’ä»˜ä¸
  const poseFrames = await attachPoseKeypoints(rawFrames, defaultDetectKeypoints);

  // â˜… 6ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºæŠ½å‡ºï¼ˆaddress / backswing / top / downswing / impact / finishï¼‰
  const sixPhaseFrames = determineSwingPhases(poseFrames);

  const vision = await askVisionAPI({
    frames: sixPhaseFrames, // Vision ã¯ä»£è¡¨6ãƒ•ã‚§ãƒ¼ã‚ºã®ã¿ã‚’è§£æ
    prompt: SWING_ANALYSIS_PROMPT,
  });

  let parsed = vision;
  if (typeof parsed === "string") {
    try {
      parsed = JSON.parse(parsed);
    } catch {
      console.error("Vision JSON parse failed:", parsed);
    }
  }

  const result = { frames: sixPhaseFrames, rawFrames, vision: parsed };

  // Next.js ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸è‡ªå‹•ã§ä¼æ¬ã™ã‚‹
  return result;
}

