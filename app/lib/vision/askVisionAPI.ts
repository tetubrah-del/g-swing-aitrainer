import { PhaseFrame } from "./extractPhaseFrames";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OPENAI_API_BASE = process.env.OPENAI_API_BASE ?? "https://api.openai.com/v1";
const OPENAI_MODEL = process.env.OPENAI_MODEL ?? "gpt-4o";

// ç”»åƒä¾å­˜åˆ†æã‚’å¼·åˆ¶ã™ã‚‹å¼·åŠ›ãª system ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
const SYSTEM_ROLE = `
ã‚ãªãŸã¯ã‚´ãƒ«ãƒ•ã‚¹ã‚¤ãƒ³ã‚°ã®åˆ†æå°‚é–€ AI ã§ã™ã€‚
æä¾›ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã®ã¿ã‚’æ ¹æ‹ ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
ä¸€èˆ¬è«–ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ã¯ç¦æ­¢ã§ã™ã€‚
å¿…ãš JSON ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
`;

function assertEnv(value: string | undefined, name: string): string {
  if (!value) {
    throw new Error(`${name} is not set`);
  }
  return value;
}

export interface AskVisionAPIParams {
  frames: PhaseFrame[];
  prompt: string;
}

// New OpenAI Vision Chat Completions message content type for requests
type OpenAIRequestMessageContent =
  | { type: "text"; text: string }
  | { type: "image_url"; image_url: { url: string } };

type OpenAIResponseMessageContent = string | object;

export async function askVisionAPI({ frames, prompt }: AskVisionAPIParams): Promise<unknown> {
  const apiKey = assertEnv(OPENAI_API_KEY, "OPENAI_API_KEY");
  const model = OPENAI_MODEL === "gpt-4o" || OPENAI_MODEL === "gpt-4o-mini" ? OPENAI_MODEL : "gpt-4o";
  const limitedFrames = frames.slice(0, 6);
  const enhancedPrompt = `${prompt}

â€»ä»¥ä¸‹ã®ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ ã®å†…å®¹ã‚’ä¸»ã«å‚ç…§ã—ã¦åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçš„ãªæ–‡ç« ã§ã¯ãªãã€ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®å‹•ãã«å³ã—ãŸå…·ä½“çš„ãªæ—¥æœ¬èªåˆ†æã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
å¿…ãš JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã€å‰å¾Œã®ã‚³ãƒ¡ãƒ³ãƒˆã¯ç¦æ­¢ã—ã¾ã™ã€‚
`;

  // ğŸ”¥ OpenAI Vision æ­£ã—ã„ content æ§‹é€ 
  const content: OpenAIRequestMessageContent[] = [];

  content.push({
    type: "text",
    text: enhancedPrompt,
  });

  // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æœ€å¤§5æšã¾ã§ç”»åƒã¨ã—ã¦è¿½åŠ ï¼ˆé †åºã‚’ä¿æŒï¼‰
  for (const frame of limitedFrames) {
    if (!frame?.base64Image || !frame?.mimeType) continue;
    content.push({
      type: "image_url",
      image_url: {
        url: `data:${frame.mimeType};base64,${frame.base64Image}`,
      },
    });
  }

  // Vision ãŒç”»åƒå¾Œã«åˆ¶å¾¡æ–‡ã‚’èª­ã‚“ã ã»ã†ãŒå¾“ã†ãŸã‚ã€è£œå¼·ã®ãŸã‚ã«1è¡Œè¿½åŠ 
  content.push({
    type: "text",
    text: "â€»å‡ºåŠ›ã¯ JSON ã®ã¿ï¼ˆæ—¥æœ¬èªï¼‰ã€ãƒ†ãƒ³ãƒ—ãƒ¬ã§ã¯ãªããƒ•ãƒ¬ãƒ¼ãƒ è¦³å¯Ÿã«åŸºã¥ãå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚",
  });

  const payload = {
    model,
    // system ã‚’å…ˆé ­ã«è¿½åŠ ã— Vision ã®æŒ™å‹•ã‚’å›ºå®šåŒ–
    messages: [
      {
        role: "system" as const,
        content: SYSTEM_ROLE,
      },
      {
        role: "user" as const,
        content,
      },
    ],
    response_format: {
      type: "json_object",
    },
  };

  const response = await fetch(`${OPENAI_API_BASE}/chat/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify(payload),
  });

  if (!response.ok) {
    const errorBody = await response.text().catch(() => "");
    throw new Error(`OpenAI API request failed: ${response.status} ${response.statusText} ${errorBody}`);
  }

  const data = (await response.json()) as {
    choices?: Array<{ message?: { content?: OpenAIResponseMessageContent } }>;
    error?: unknown;
  };
  const rawContent = data?.choices?.[0]?.message?.content ?? null;

  // Vision ã® content ãŒ object / string ä¸¡å¯èƒ½æ€§ã«å¯¾å¿œ
  if (typeof rawContent === "object" && rawContent !== null) {
    return rawContent;
  }

  if (typeof rawContent === "string") {
    try {
      return JSON.parse(rawContent);
    } catch {
      console.error("askVisionAPI JSON parse fail:", rawContent);
      return rawContent;
    }
  }

  return rawContent;
}
